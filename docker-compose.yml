services:
  # Internal PostgreSQL database for storing collected queries and analysis results
  internal-db:
    image: postgres:15
    container_name: ai-analyzer-internal-db
    restart: unless-stopped
    environment:
      POSTGRES_USER: ai_core
      POSTGRES_PASSWORD: ai_core
      POSTGRES_DB: ai_core
    ports:
      - "5440:5432"
    volumes:
      - ./data/internal-db:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_core"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis for caching and task queue (optional for APScheduler, required for Celery)
  redis:
    image: redis:7-alpine
    container_name: ai-analyzer-redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # FastAPI Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: ai-analyzer-backend
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # Internal DB connection (multi-tenant)
      DB_TYPE: postgresql
      DB_HOST: internal-db
      DB_PORT: 5432
      DB_USER: ai_core
      DB_PASSWORD: ai_core
      DB_NAME: ai_core

      # Legacy naming (for backward compatibility)
      INTERNAL_DB_HOST: internal-db
      INTERNAL_DB_PORT: 5432
      INTERNAL_DB_USER: ai_core
      INTERNAL_DB_PASSWORD: ai_core
      INTERNAL_DB_NAME: ai_core

      # Redis connection
      REDIS_HOST: redis
      REDIS_PORT: 6379

      # Lab databases (external)
      MYSQL_HOST: host.docker.internal
      MYSQL_PORT: 3307
      MYSQL_USER: root
      MYSQL_PASSWORD: root
      MYSQL_DB: labdb

      PG_HOST: host.docker.internal
      PG_PORT: 5433
      PG_USER: postgres
      PG_PASSWORD: root
      PG_DB: labdb

      # Application settings
      LOG_LEVEL: INFO
      ENV: development

      # JWT settings (must match api-gateway)
      JWT_SECRET_KEY: your-secret-key-change-in-production
      JWT_ALGORITHM: HS256

      # AI Provider Settings (optional)
      # Set AI_PROVIDER to 'openai' to enable AI-powered analysis
      # Leave as 'stub' for rule-based analysis only
      AI_PROVIDER: stub
      # AI_API_KEY: your-openai-api-key-here
      AI_MODEL: gpt-4
    depends_on:
      internal-db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
    extra_hosts:
      - "host.docker.internal:host-gateway"

  # AI Analyzer (OpenAI/Ollama microservice)
  ai-analyzer:
    build:
      context: ./ai-analyzer
      dockerfile: Dockerfile
    container_name: ai-analyzer-service
    restart: unless-stopped
    ports:
      - "8001:8001"
    environment:
      # AI Model configuration
      MODEL_PROVIDER: stub  # openai, ollama, or stub
      MODEL_NAME: gpt-4
      # MODEL_API_KEY: your-openai-api-key-here
      # MODEL_API_BASE_URL: http://ollama:11434  # For Ollama on-premise
      LOG_LEVEL: INFO
      REQUIRE_AUTHENTICATION: false  # Disable auth for internal service
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # API Gateway (rate limiting, auth, routing)
  api-gateway:
    build:
      context: ./api-gateway
      dockerfile: Dockerfile
    container_name: ai-analyzer-gateway
    restart: unless-stopped
    ports:
      - "8082:8000"
    environment:
      # Service configuration
      SERVICE_NAME: dbpower-api-gateway
      HOST: 0.0.0.0
      PORT: 8000

      # Backend services
      BACKEND_URL: http://backend:8000
      AI_ANALYZER_URL: http://ai-analyzer:8001

      # Redis for rate limiting
      REDIS_URL: redis://redis:6379/0

      # JWT settings (must match backend)
      JWT_SECRET_KEY: your-secret-key-change-in-production
      JWT_ALGORITHM: HS256

      # Rate limiting
      RATE_LIMIT_REQUESTS_PER_MINUTE: 100
      RATE_LIMIT_REQUESTS_PER_HOUR: 1000

      LOG_LEVEL: INFO
    depends_on:
      backend:
        condition: service_started
      ai-analyzer:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Admin Panel (React frontend)
  admin-panel:
    build:
      context: ./admin-panel
      dockerfile: Dockerfile
    container_name: ai-analyzer-admin-panel
    restart: unless-stopped
    ports:
      - "3001:80"
    depends_on:
      api-gateway:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # React Frontend (DBPower Base - LLaMA Edition with Auth)
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: ai-analyzer-frontend
    restart: unless-stopped
    ports:
      - "3000:80"
    environment:
      VITE_API_URL: http://localhost:8000
    depends_on:
      - backend
    volumes:
      - ./frontend:/app
      - /app/node_modules

networks:
  default:
    name: ai-analyzer-network
